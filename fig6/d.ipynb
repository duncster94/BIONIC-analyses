{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 6. d) analysis\n",
    "\n",
    "This notebook generates the data used to create the Fig. 6 d) circle packing plot. The actual plot was created using D3.js. An Observable notebook that implements the plotting can be found [here](https://observablehq.com/@duncster94/fig-6-d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, maxdists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import BIONIC features, Costanzo bioprocesses, IntAct protein complexes, and TS genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import BIONIC features\n",
    "features = pd.read_csv(\"../data/methods/yeast_BIONIC_features.csv\", index_col=0)\n",
    "\n",
    "# import Costanzo bioprocesses\n",
    "with Path(\"../data/standards/Costanzo-bioprocess.json\").open(\"r\") as f:\n",
    "    bioprocesses = json.load(f)\n",
    "\n",
    "# import IntAct complex standard\n",
    "with Path(\"../data/standards/yeast-IntAct-complex-modules.json\").open(\"r\") as f:\n",
    "    complexes = json.load(f)\n",
    "\n",
    "# import list of genes for which we have TS alleles for\n",
    "ts_genes = list(pd.read_csv(\"../data/chemical-genetics/TS-genes.txt\", header=None, sep=\"\\n\")[0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset `features` to only contain genes in `ts_genes` and genes in the \"Glycosylation, protein folding/targeting, cell wall biosynthesis\" bioprocess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get genes in bioprocess\n",
    "bioprocess = \"Glycosylation, protein folding/targeting, cell wall biosynthesis\"\n",
    "bioprocess_genes = bioprocesses[bioprocess]\n",
    "\n",
    "# find common genes\n",
    "ts_genes_in_biop = np.intersect1d(ts_genes, bioprocess_genes)\n",
    "common_genes = np.intersect1d(ts_genes_in_biop, list(features.index))\n",
    "\n",
    "# subset `features`\n",
    "features = features.reindex(common_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster the BIONIC features, but don't extract clusters yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = linkage(features.values, method=\"average\", metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will extract clusters from `link` at two different levels. The first (lowest) level will contain clusters that correspond to protein complexes (i.e. adaptive cluter thresholds), where as the second (highest) level will simply be a flat threshold.\n",
    "\n",
    "First we define a function to identify protein complexes in `link` (the first, lowest level). For each protein complex present in the \"Glycosylation, protein folding/targeting, cell wall biosynthesis\" bioprocess, this function identifies the clustering threhold that best matches said complex. For genes which do not fit into a known complex, a flat clustering threshold given by `highest_thresh` will be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_level_clusters(complexes):\n",
    "\n",
    "    # find maximum allowable clustering threshold\n",
    "    max_thresh = np.max(maxdists(link))\n",
    "    \n",
    "    assignments = {}\n",
    "    highest_thresh = 0  # highest threshold found so far\n",
    "\n",
    "    # iterate over protein complexes and identify best matching cluters\n",
    "    for complex, comp_genes in complexes.items():\n",
    "\n",
    "        # skip if the protein complex has fewer than 2 members in `common_genes`\n",
    "        if len(np.intersect1d(comp_genes, common_genes)) < 2:\n",
    "            continue\n",
    "\n",
    "        # keep track of the best cluster-complex overlap score (Jaccard)\n",
    "        best_jaccard = 0\n",
    "\n",
    "        # iterate over cluster thresholds `t` and find thresholds that best match\n",
    "        # the known complex given by `comp_genes`\n",
    "        for thresh in np.linspace(0, max_thresh, num=1000):\n",
    "\n",
    "            # extract clusters\n",
    "            clusters = fcluster(link, thresh, criterion=\"distance\")\n",
    "\n",
    "            # get unique indices corresponding to `clusters`\n",
    "            labels = np.unique(clusters)\n",
    "\n",
    "            # iterate over each cluster assignment and compare cluster with complex\n",
    "            for label in labels:\n",
    "\n",
    "                # get gene indices corresponding to cluster given by `label`\n",
    "                cluster = np.argwhere(clusters == label).flatten()\n",
    "\n",
    "                # ignore clusters with fewer than 2 members\n",
    "                if len(cluster) < 2:\n",
    "                    continue\n",
    "\n",
    "                # get genes from indices\n",
    "                cluster_genes = common_genes[cluster]\n",
    "\n",
    "                # compute Jaccard score numerator and denominator by comparing cluster with complex\n",
    "                numer = len(np.intersect1d(cluster_genes, comp_genes))\n",
    "                denom = len(np.union1d(cluster_genes, comp_genes))\n",
    "\n",
    "                if denom == 0:\n",
    "                    jaccard = 0\n",
    "                else:\n",
    "                    jaccard = numer / denom\n",
    "\n",
    "                # check the Jaccard score is the best so far, and that the complex \n",
    "                # is considered \"captured\" (Jaccard score >= 0.5)\n",
    "                if jaccard > best_jaccard and jaccard >= 0.5:\n",
    "                    if thresh > highest_thresh:\n",
    "                        highest_thresh = thresh\n",
    "                    best_jaccard = jaccard\n",
    "\n",
    "                    # update the cluster assignment for the given complex\n",
    "                    assignments[complex] = cluster\n",
    "\n",
    "    # create an array of indices corresponding to the captured complexes\n",
    "    gene_assignments = np.zeros(len(common_genes))\n",
    "    print(\"Captured complexes:\")\n",
    "    for i, (complex, idxs) in enumerate(assignments.items()):\n",
    "        print(complex)\n",
    "        gene_assignments[idxs] = i + 1\n",
    "\n",
    "    # combine `gene_assignments` with clusters obtained by extracting at `highest_thresh`\n",
    "    # we add 0.1 to `highest_thresh` so that there are fewer split clusters (better visualization)\n",
    "    final_clusters = (\n",
    "        np.max(gene_assignments) + 1 + fcluster(link, highest_thresh + 0.1, criterion=\"distance\")\n",
    "    )\n",
    "    final_clusters[np.nonzero(gene_assignments)] = gene_assignments[np.nonzero(gene_assignments)]\n",
    "\n",
    "    return final_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate clusters from the first and second levels. We also include a \"zeroth\" level cluster set that corresponds to all singleton clusters. This is done simply to align the indices from clsuter assignments in the first and second levels to the genes in `common_genes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured complexes:\n",
      "CPX-1643\n",
      "CPX-3056\n",
      "CPX-1269\n"
     ]
    }
   ],
   "source": [
    "first_level_clusters = get_first_level_clusters(complexes)\n",
    "\n",
    "# cluster threshold 0.9 is arbitrary and chosen simply to show higher order organization\n",
    "second_level_clusters = fcluster(link, 0.9, criterion=\"distance\")\n",
    "\n",
    "# get singleton cluster assignments\n",
    "zeroth_level_clusters = fcluster(link, 0, criterion=\"distance\")\n",
    "\n",
    "# create the final set of clusters\n",
    "clusters = [zeroth_level_clusters, first_level_clusters, second_level_clusters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a dictionary in the correct format for D3.js to use for visualization. This is accomplished by recursively building the dictionary from the top down. We also map genes from ORFs to gene names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import name mapping dictionary\n",
    "with Path(\"../data/chemical-genetics/yeast-orf2name-mapper.json\").open(\"r\") as f:\n",
    "    orf2name_mapper = json.load(f)\n",
    "mapped_genes = np.array([orf2name_mapper[gene] if gene in orf2name_mapper else gene for gene in common_genes])\n",
    "\n",
    "# define recursive dictionary builder\n",
    "def create_data_structure_recursive(clusters, subset, idx):\n",
    "\n",
    "    if idx + 1 > len(clusters):\n",
    "        names = mapped_genes[subset]\n",
    "        return [{\"name\": name, \"value\": 1} for name in names]\n",
    "\n",
    "    cluster = clusters[idx]\n",
    "    cluster_ = cluster[subset]\n",
    "    labels = np.unique(cluster_)\n",
    "    children = []\n",
    "\n",
    "    for label in labels:\n",
    "\n",
    "        # get indices of `cluster` which equal label\n",
    "        new_subset = np.argwhere(clusters[idx] == label).flatten()\n",
    "        child = create_data_structure_recursive(clusters, new_subset, idx + 1)\n",
    "        if isinstance(child, list):\n",
    "            children += child\n",
    "        else:\n",
    "            children.append(child)\n",
    "    return {\"name\": \"\", \"children\": children}\n",
    "\n",
    "# define recursive wrapper function\n",
    "def create_data_structure(clusters):\n",
    "\n",
    "    # reverse `clusters`\n",
    "    clusters = clusters[::-1]\n",
    "\n",
    "    return create_data_structure_recursive(clusters, np.arange(len(clusters[0])), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dictionary used in the D3.js visualization. This matches the \"clusters_Glycosylation, protein folding-targeting, cell wall biosynthesis.json\" file used in the D3.js visualization. Implementation of the visualization can be found [here](https://observablehq.com/@duncster94/fig-6-d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '',\n",
       " 'children': [{'name': '',\n",
       "   'children': [{'name': '',\n",
       "     'children': [{'name': 'CDS1', 'value': 1}, {'name': 'COP1', 'value': 1}]},\n",
       "    {'name': '',\n",
       "     'children': [{'name': 'GDI1', 'value': 1}, {'name': 'MRS6', 'value': 1}]},\n",
       "    {'name': '', 'children': [{'name': 'FRQ1', 'value': 1}]}]},\n",
       "  {'name': '',\n",
       "   'children': [{'name': '',\n",
       "     'children': [{'name': 'ALG14', 'value': 1},\n",
       "      {'name': 'ALG13', 'value': 1}]},\n",
       "    {'name': '',\n",
       "     'children': [{'name': 'SEC63', 'value': 1},\n",
       "      {'name': 'SEC62', 'value': 1}]},\n",
       "    {'name': '',\n",
       "     'children': [{'name': 'GPI18', 'value': 1},\n",
       "      {'name': 'PGA1', 'value': 1}]},\n",
       "    {'name': '',\n",
       "     'children': [{'name': 'NUS1', 'value': 1},\n",
       "      {'name': 'SEC59', 'value': 1},\n",
       "      {'name': 'DPM1', 'value': 1}]},\n",
       "    {'name': '', 'children': [{'name': 'PMI40', 'value': 1}]},\n",
       "    {'name': '', 'children': [{'name': 'ALG2', 'value': 1}]},\n",
       "    {'name': '',\n",
       "     'children': [{'name': 'ERD2', 'value': 1},\n",
       "      {'name': 'ERO1', 'value': 1},\n",
       "      {'name': 'OST2', 'value': 1},\n",
       "      {'name': 'OST1', 'value': 1},\n",
       "      {'name': 'KAR2', 'value': 1}]},\n",
       "    {'name': '', 'children': [{'name': 'SWP1', 'value': 1}]},\n",
       "    {'name': '',\n",
       "     'children': [{'name': 'SSS1', 'value': 1}, {'name': 'SPC3', 'value': 1}]},\n",
       "    {'name': '', 'children': [{'name': 'PKC1', 'value': 1}]},\n",
       "    {'name': '', 'children': [{'name': 'TPT1', 'value': 1}]},\n",
       "    {'name': '',\n",
       "     'children': [{'name': 'GPI19', 'value': 1},\n",
       "      {'name': 'GPI2', 'value': 1},\n",
       "      {'name': 'GPI17', 'value': 1},\n",
       "      {'name': 'GAB1', 'value': 1},\n",
       "      {'name': 'GAA1', 'value': 1},\n",
       "      {'name': 'GPI15', 'value': 1},\n",
       "      {'name': 'GWT1', 'value': 1},\n",
       "      {'name': 'GPI11', 'value': 1},\n",
       "      {'name': 'GPI10', 'value': 1},\n",
       "      {'name': 'GPI13', 'value': 1},\n",
       "      {'name': 'SMP3', 'value': 1},\n",
       "      {'name': 'GPI8', 'value': 1},\n",
       "      {'name': 'GPI16', 'value': 1}]},\n",
       "    {'name': '',\n",
       "     'children': [{'name': 'WBP1', 'value': 1}, {'name': 'STT3', 'value': 1}]},\n",
       "    {'name': '',\n",
       "     'children': [{'name': 'BIG1', 'value': 1},\n",
       "      {'name': 'KRE5', 'value': 1},\n",
       "      {'name': 'KRE9', 'value': 1},\n",
       "      {'name': 'ROT1', 'value': 1}]},\n",
       "    {'name': '', 'children': [{'name': 'TRS130', 'value': 1}]},\n",
       "    {'name': '', 'children': [{'name': 'RNT1', 'value': 1}]},\n",
       "    {'name': '', 'children': [{'name': 'PAN1', 'value': 1}]}]},\n",
       "  {'name': '',\n",
       "   'children': [{'name': '', 'children': [{'name': 'CMD1', 'value': 1}]},\n",
       "    {'name': '', 'children': [{'name': 'ERG27', 'value': 1}]}]},\n",
       "  {'name': '',\n",
       "   'children': [{'name': '', 'children': [{'name': 'ERG10', 'value': 1}]}]},\n",
       "  {'name': '',\n",
       "   'children': [{'name': '', 'children': [{'name': 'IPP1', 'value': 1}]}]},\n",
       "  {'name': '',\n",
       "   'children': [{'name': '', 'children': [{'name': 'SRP101', 'value': 1}]}]}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = create_data_structure(clusters)\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f1142d212e6e8cceef5b4a22ed61237952f6fb2a7c6aecb63226793aae517a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('bionic-evals': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
