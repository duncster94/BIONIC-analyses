{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4. analysis\n",
    "\n",
    "Co-annotation prediction, module detection and gene function prediction evaluation code can be run using the **BIONIC-evals** library from [this](https://github.com/duncster94/BIONIC-evals) respository. The README provides instructions on installing and running the library. A config file is provided to replicate the performance evaluations from Fig. 4.\n",
    "\n",
    "**NOTE:** The module detection and gene function prediction evaluations are computationally intensive and take a long time to run. I am happy to implement multiprocessing support to speed these up - if you are interested in this feature please open an [issue](https://github.com/duncster94/BIONIC-evals/issues).\n",
    "\n",
    "This notebook contains the dataset splitting procedure used to generate the training and corresponding testing sets for the co-annotation prediction, module detection, and gene function prediction evaluations.\n",
    "\n",
    "Please also **NOTE** that due to the size of the co-annotation files and GitHub's file size constraints, I have opted to show the splitting process for IntAct only. The train/test splitting process detailed in this notebook is identical for GO and KEGG however, and can be applied to those standards with the corresponding input files (available [here](https://figshare.com/articles/dataset/Evaluation_Standards/16629139))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "output_path = Path(\"../data/standards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define co-annotation standard splitting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_coannotation(standard: pd.DataFrame, test_genes: set, trial: int, name: str, save: bool = False):\n",
    "    print(\"Splitting co-annotation...\")\n",
    "    test_standard = []\n",
    "\n",
    "    for row in standard.itertuples():\n",
    "        gene_1, gene_2 = row[1], row[2]\n",
    "        if gene_1 in test_genes or gene_2 in test_genes:\n",
    "            test_standard.append(row[1:])\n",
    "\n",
    "    test_standard = pd.DataFrame(test_standard)\n",
    "\n",
    "    if save:\n",
    "        test_standard.to_csv(\n",
    "            output_path / f\"{name}-coannotation-test-{trial}.csv\", index=False, header=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define module standard splitting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_module(standard: dict, test_genes: set, trial: int, name: str, save: bool = False):\n",
    "    print(\"Splitting module...\")\n",
    "\n",
    "    test_standard = {}\n",
    "    standard_genes = []\n",
    "\n",
    "\n",
    "    for module, genes in standard.items():\n",
    "        standard_genes += genes\n",
    "        genes_ = set(genes)\n",
    "        if len(genes_.intersection(test_genes)) > 0:\n",
    "            test_standard[module] = genes\n",
    "\n",
    "    if save:\n",
    "        with (output_path / f\"{name}-module-test-{trial}.json\").open(\"w\") as f:\n",
    "            json.dump(test_standard, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define gene function prediction splitting function. This function also produces the training set (used by BIONIC) for the given split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_supervised(standard: dict, test_genes: set, trial: int, name: str, save: bool = False):\n",
    "    print(\"Splitting supervised...\")\n",
    "\n",
    "    test_standard = {gene: complexes for gene, complexes in standard.items() if gene in test_genes}\n",
    "    train_standard = {gene: complexes for gene, complexes in standard.items() if gene not in test_genes}\n",
    "\n",
    "    if save:\n",
    "        with (output_path /  f\"{name}-supervised-test-{trial}.json\").open(\"w\") as f:\n",
    "            json.dump(test_standard, f)\n",
    "        with (output_path /  f\"{name}-supervised-train-{trial}.json\").open(\"w\") as f:\n",
    "            json.dump(train_standard, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import IntAct standards and run the splitting functions. To save the outputs of this notebook `save=True` should be passed to each splitting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0\n",
      "Splitting co-annotation...\n",
      "Splitting module...\n",
      "Splitting supervised...\n",
      "\n",
      "\n",
      "Trial: 1\n",
      "Splitting co-annotation...\n",
      "Splitting module...\n",
      "Splitting supervised...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_trials = 10\n",
    "test_size = 0.2  # 20% test size\n",
    "\n",
    "coannotation = pd.read_csv(output_path / \"yeast-IntAct-complex-coannotation.csv\", header=None)\n",
    "\n",
    "with (output_path / \"yeast-IntAct-complex-modules.json\").open(\"r\") as f:\n",
    "    module = json.load(f)\n",
    "\n",
    "with (output_path / \"yeast-IntAct-complex-labels.json\").open(\"r\") as f:\n",
    "    supervised = json.load(f)  # gene function prediction standard\n",
    "\n",
    "genes = list(set(supervised.keys()))\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    print(f\"Trial: {trial}\")\n",
    "    shuffled_genes = np.array(genes)\n",
    "    np.random.shuffle(shuffled_genes)\n",
    "    train_size = math.floor((1 - test_size) * len(shuffled_genes))\n",
    "\n",
    "    train_genes = shuffled_genes[:train_size]\n",
    "    test_genes = set(shuffled_genes[train_size:])\n",
    "\n",
    "    # pass `save=True` to save results\n",
    "    split_coannotation(coannotation, test_genes=test_genes, trial=trial, name=\"IntAct\")\n",
    "    split_module(module, test_genes=test_genes, trial=trial, name=\"IntAct\")\n",
    "    split_supervised(supervised, test_genes=test_genes, trial=trial, name=\"IntAct\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f1142d212e6e8cceef5b4a22ed61237952f6fb2a7c6aecb63226793aae517a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('bionic-evals': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
